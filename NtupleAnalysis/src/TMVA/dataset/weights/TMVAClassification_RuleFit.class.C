// Class: ReadRuleFit
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : RuleFit::RuleFit
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.10/08       [395784]
Creator        : attikis
Date           : Wed Nov  1 12:39:15 2017
Host           : Darwin MacBook-13.local 17.0.0 Darwin Kernel Version 17.0.0: Thu Aug 24 21:48:19 PDT 2017; root:xnu-4570.1.46~2/RELEASE_X86_64 x86_64
Dir            : /Users/attikis/my_work/cms/lxplus/hltaus/HLTausAnalysis/NtupleAnalysis/src/TMVA
Training events: 2000
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "True" [Print method-specific help message]
GDTau: "-1.000000e+00" [Gradient-directed (GD) path: default fit cut-off]
GDTauPrec: "1.000000e-02" [GD path: precision of tau]
GDStep: "1.000000e-02" [GD path: step size]
GDNSteps: "10000" [GD path: number of steps]
GDErrScale: "1.020000e+00" [Stop scan when error > scale*errmin]
fEventsMin: "1.000000e-02" [Minimum fraction of events in a splittable node]
fEventsMax: "5.000000e-01" [Maximum fraction of events in a splittable node]
nTrees: "20" [Number of trees in forest.]
RuleMinDist: "1.000000e-03" [Minimum distance between rules]
MinImp: "1.000000e-03" [Minimum rule importance accepted]
Model: "modrulelinear" [Model to be used]
RuleFitModule: "rftmva" [Which RuleFit module to use]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
LinQuantile: "2.500000e-02" [Quantile of linear terms (removes outliers)]
GDPathEveFrac: "5.000000e-01" [Fraction of events used for the path search]
GDValidEveFrac: "5.000000e-01" [Fraction of events used for the validation]
ForestType: "adaboost" [Method to use for forest generation (AdaBoost or RandomForest)]
RFWorkDir: "./rulefit" [Friedman's RuleFit module (RFF): working dir]
RFNrules: "2000" [RFF: Mximum number of rules]
RFNendnodes: "4" [RFF: Average number of end nodes]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 4
L1Tks_Pt                      L1Tks_Pt                      L1Tks_Pt                      L1Tks_Pt                      GeV/c                             'F'    [1.82206881046,2261.17944336]
L1Tks_Eta                     L1Tks_Eta                     L1Tks_Eta                     L1Tks_Eta                                                       'F'    [-2.51387381554,2.50433182716]
L1Tks_POCAz                   L1Tks_POCAz                   L1Tks_POCAz                   L1Tks_POCAz                   cm                                'F'    [-22.0277004242,20.6650104523]
L1Tks_ChiSquared              L1Tks_ChiSquared              L1Tks_ChiSquared              L1Tks_ChiSquared                                                'F'    [0.0322723351419,1179.91040039]
NSpec 0


============================================================================ */

#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadRuleFit : public IClassifierReader {

 public:

   // constructor
   ReadRuleFit( std::vector<std::string>& theInputVars ) 
      : IClassifierReader(),
        fClassName( "ReadRuleFit" ),
        fNvars( 4 ),
        fIsNormalised( false )
   {      
      // the training input variables
      const char* inputVars[] = { "L1Tks_Pt", "L1Tks_Eta", "L1Tks_POCAz", "L1Tks_ChiSquared" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;
      fVmin[3] = 0;
      fVmax[3] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';
      fType[3] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadRuleFit() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the 
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   const bool fIsNormalised;
   bool IsNormalised() const { return fIsNormalised; }
   double fVmin[4];
   double fVmax[4];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[4];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   // not implemented for class: "ReadRuleFit"
};
void   ReadRuleFit::Initialize(){}
void   ReadRuleFit::Clear(){}
double ReadRuleFit::GetMvaValue__( const std::vector<double>& inputValues ) const {
   double rval=2.440491892;
   //
   // here follows all rules ordered in importance (most important first)
   // at the end of each line, the relative importance of the rule is given
   //
   if ((5.540462017<inputValues[0])&&(inputValues[3]<56.21694565)) rval+=0.8249136518;   // importance = 0.138
   if ((inputValues[0]<40.61323166)&&(inputValues[3]<56.21694565)) rval+=-0.6952820244;   // importance = 0.104
   if ((-1.796987295<inputValues[1])) rval+=-0.717582681;   // importance = 0.092
   if ((inputValues[3]<56.21694565)) rval+=-0.6891295763;   // importance = 0.087
   if ((-3.730824232<inputValues[2])) rval+=-0.4971344741;   // importance = 0.068
   if ((-1.558025122<inputValues[1])&&(inputValues[2]<1.805410981)) rval+=-0.3367529531;   // importance = 0.058
   if ((inputValues[2]<2.36813426)) rval+=-0.3269228416;   // importance = 0.052
   if ((-2.035949469<inputValues[1])&&(-3.730824232<inputValues[2])&&(inputValues[2]<2.848829746)) rval+=0.2924704564;   // importance = 0.051
   if ((-0.1428836882<inputValues[1])&&(inputValues[3]<56.21694565)) rval+=-0.2880162629;   // importance = 0.049
   if ((inputValues[1]<1.7843045)&&(-3.730824232<inputValues[2])) rval+=-0.3042022214;   // importance = 0.048
   if ((18.36399651<inputValues[3])) rval+=0.2124615404;   // importance = 0.037
   if ((inputValues[1]<-0.375947684)&&(inputValues[3]<56.21694565)) rval+=-0.219040646;   // importance = 0.036
   if ((inputValues[1]<-1.558025122)) rval+=-0.2259195465;   // importance = 0.032
   if ((inputValues[1]<0.8315966129)&&(-4.244266033<inputValues[2])&&(56.21694565<inputValues[3])) rval+=-0.24138165;   // importance = 0.023
   if ((inputValues[1]<-0.1242520809)&&(inputValues[2]<-3.22600913)) rval+=-0.2059787243;   // importance = 0.022
   if ((2.719472647<inputValues[0])&&(inputValues[1]<-2.035949469)&&(inputValues[2]<2.64854002)) rval+=0.2327626318;   // importance = 0.017
   if ((inputValues[2]<2.387382269)&&(8.759391785<inputValues[3])&&(inputValues[3]<18.36399651)) rval+=-0.1212662106;   // importance = 0.017
   if ((inputValues[1]<-2.035949469)&&(0.3351481259<inputValues[2])&&(inputValues[3]<56.34256744)) rval+=-0.2232907199;   // importance = 0.016
   if ((-1.502063274<inputValues[1])&&(inputValues[1]<2.095089674)&&(-0.8039477468<inputValues[2])&&(inputValues[2]<1.669190764)) rval+=0.1175101361;   // importance = 0.015
   if ((0.3558007777<inputValues[1])&&(10.72823811<inputValues[3])) rval+=0.08172742638;   // importance = 0.013
   if ((-0.1242520809<inputValues[1])&&(inputValues[2]<-5.763810635)&&(inputValues[3]<25.43250656)) rval+=-0.1872327747;   // importance = 0.012
   if ((-1.885396242<inputValues[2])&&(inputValues[2]<0.8072475195)) rval+=0.07796171778;   // importance = 0.011
   if ((inputValues[1]<0.8315966129)&&(-4.244266033<inputValues[2])&&(inputValues[2]<1.699399352)&&(56.21694565<inputValues[3])) rval+=-0.1105532471;   // importance = 0.008
   if ((0.8315966129<inputValues[1])&&(-0.3003872335<inputValues[2])&&(56.21694565<inputValues[3])) rval+=-0.1195438223;   // importance = 0.007
   if ((inputValues[1]<0.8315966129)&&(inputValues[2]<-4.244266033)&&(56.21694565<inputValues[3])) rval+=-0.1519641156;   // importance = 0.007
   if ((inputValues[1]<0.5941566825)&&(13.40222931<inputValues[3])) rval+=-0.03174032021;   // importance = 0.005
   if ((0.1465752125<inputValues[1])&&(inputValues[1]<1.004595995)&&(-3.730824232<inputValues[2])) rval+=-0.03146934195;   // importance = 0.004
   if ((inputValues[0]<15.43288231)&&(inputValues[1]<-2.035949469)&&(inputValues[2]<0.3351481259)) rval+=-0.04014401113;   // importance = 0.003
   if ((-0.6987205744<inputValues[1])&&(inputValues[1]<-0.1242520809)&&(-3.22600913<inputValues[2])&&(inputValues[2]<3.655677319)&&(inputValues[3]<48.30544662)) rval+=-0.02818646982;   // importance = 0.002
   if ((-0.1242520809<inputValues[1])&&(inputValues[1]<1.753389597)&&(inputValues[2]<1.040302873)) rval+=-0.01479963867;   // importance = 0.002
   if ((0.8315966129<inputValues[1])&&(inputValues[2]<2.745229244)&&(56.21694565<inputValues[3])) rval+=-0.02683698222;   // importance = 0.002
   //
   // here follows all linear terms
   // at the end of each line, the relative importance of the term is given
   //
   rval+=0.1588908933*std::min( double(84.22081757), std::max( double(inputValues[0]), double(2.016857386)));   // importance = 1.000
   rval+=0.02851251983*std::min( double(2.364528179), std::max( double(inputValues[1]), double(-2.379114628)));   // importance = 0.014
   rval+=-0.01380105678*std::min( double(8.590433121), std::max( double(inputValues[2]), double(-9.370200157)));   // importance = 0.020
   rval+=-0.02435658685*std::min( double(112.4829102), std::max( double(inputValues[3]), double(2.104940176)));   // importance = 0.224
   return rval;
}
   inline double ReadRuleFit::GetMvaValue( const std::vector<double>& inputValues ) const
   {
      // classifier response value
      double retval = 0;

      // classifier response, sanity check first
      if (!IsStatusClean()) {
         std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                   << " because status is dirty" << std::endl;
         retval = 0;
      }
      else {
         if (IsNormalised()) {
            // normalise variables
            std::vector<double> iV;
            iV.reserve(inputValues.size());
            int ivar = 0;
            for (std::vector<double>::const_iterator varIt = inputValues.begin();
                 varIt != inputValues.end(); varIt++, ivar++) {
               iV.push_back(NormVariable( *varIt, fVmin[ivar], fVmax[ivar] ));
            }
            retval = GetMvaValue__( iV );
         }
         else {
            retval = GetMvaValue__( inputValues );
         }
      }

      return retval;
   }
